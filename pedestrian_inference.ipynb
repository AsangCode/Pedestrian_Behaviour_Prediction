{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/AsangCode/Pedestrian_Behaviour_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run this to initialize the required components [YOLO, SORT and DenseNet]\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "!pip install filterpy\n",
    "%cd Pedestrian_Behaviour_Prediction\n",
    "\n",
    "import sys\n",
    "from absl import app, logging, flags\n",
    "from absl.flags import FLAGS\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from yolov3_tf2.models import (\n",
    "    YoloV3, YoloV3Tiny\n",
    ")\n",
    "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
    "from yolov3_tf2.utils import draw_outputs\n",
    "\n",
    "from sortn import *\n",
    "\n",
    "flags.DEFINE_string('classes', '/content/Pedestrian_Behaviour_Prediction/data/coco.names', 'path to classes file')\n",
    "flags.DEFINE_string('weights', '/content/Pedestrian_Behaviour_Prediction/yolov3_train_3.weights.h5','path to weights file')\n",
    "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
    "flags.DEFINE_integer('num_classes', 1, 'number of classes in the model')\n",
    "flags.DEFINE_string('video', '/content/Pedestrian_Behaviour_Prediction/data/JAAD_test_video_0339.mp4','path to video file or number for webcam)')\n",
    "flags.DEFINE_string('output','Result.mp4', 'path to output video')\n",
    "flags.DEFINE_string('output_format', 'mp4v', 'codec used in VideoWriter when saving video to file')\n",
    "\n",
    "app._run_init(['yolov3'], app.parse_flags_with_usage)\n",
    "\n",
    "#Reading the model from JSON file\n",
    "with open('densenet_model.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "\n",
    "model_j = tf.keras.models.model_from_json(json_savedModel)\n",
    "model_j.load_weights('densenet_1.hdf5')\n",
    "\n",
    "def pred_func(X_test):\n",
    "  predictions = model_j.predict(X_test[0:1], verbose=0)\n",
    "  Y = np.argmax(predictions[0], axis=0)\n",
    "\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_annotations(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    gt_data = {}\n",
    "\n",
    "    for box in root.findall('.//box'):\n",
    "        frame = int(box.attrib['frame'])\n",
    "        xtl, ytl, xbr, ybr = float(box.attrib['xtl']), float(box.attrib['ytl']), float(box.attrib['xbr']), float(box.attrib['ybr'])\n",
    "\n",
    "        cross_element = box.find('.//attribute[@name=\"cross\"]')  # Find cross attribute\n",
    "\n",
    "        if cross_element is not None and cross_element.text is not None:\n",
    "            cross = cross_element.text.lower()\n",
    "            cross_label = 1 if cross == \"crossing\" else 0  # Convert label to binary\n",
    "        else:\n",
    "            cross_label = 0  # Default to non-crossing if missing\n",
    "\n",
    "        bbox = [xtl, ytl, xbr, ybr]  # Bounding box coordinates\n",
    "\n",
    "        if frame not in gt_data:\n",
    "            gt_data[frame] = []\n",
    "\n",
    "        gt_data[frame].append({\"bbox\": bbox, \"cross\": cross_label})\n",
    "\n",
    "    return gt_data\n",
    "\n",
    "# Example usage\n",
    "gt_annotations = parse_annotations(\"/content/Pedestrian_Behaviour_Prediction/data/video_0339.xml\")\n",
    "print(gt_annotations.get(127, \"No annotations for this frame\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save\n",
    "with open(\"gt_annotations.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gt_annotations, f)\n",
    "\n",
    "# Load later\n",
    "with open(\"gt_annotations.pkl\", \"rb\") as f:\n",
    "    gt_annotations = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Run this\n",
    "FLAGS.yolo_iou_threshold = 0.5\n",
    "FLAGS.yolo_score_threshold = 0.5\n",
    "\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "yolo = YoloV3(classes=FLAGS.num_classes)\n",
    "\n",
    "yolo.load_weights(FLAGS.weights)\n",
    "logging.info('weights loaded')\n",
    "\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
    "logging.info('classes loaded')\n",
    "\n",
    "\n",
    "\n",
    "def run_model():\n",
    "\n",
    "  start_time = time.time()  # Start time of execution\n",
    "\n",
    "  print('Processing started.......')\n",
    "  frame = 0\n",
    "\n",
    "  try:\n",
    "      vid = cv2.VideoCapture(int(FLAGS.video))\n",
    "  except:\n",
    "      vid = cv2.VideoCapture(FLAGS.video)\n",
    "\n",
    "  out = None\n",
    "\n",
    "  if FLAGS.output:\n",
    "      # by default VideoCapture returns float instead of int\n",
    "      width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "      height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "      fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "      codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)\n",
    "      out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))\n",
    "\n",
    "  #create instance of SORT\n",
    "  mot_tracker = Sort()\n",
    "  rolling_data={}\n",
    "  predictions = {}\n",
    "\n",
    "  while True:\n",
    "    _, img = vid.read()\n",
    "\n",
    "    if img is None:\n",
    "        break\n",
    "\n",
    "    frame +=1\n",
    "\n",
    "\n",
    "    preprocess_start = time.time()\n",
    "\n",
    "    img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_orig = np.copy(img)\n",
    "    img_in = tf.expand_dims(img_in, 0)\n",
    "    img_in = transform_images(img_in, FLAGS.size)\n",
    "\n",
    "    preprocess_end = time.time()\n",
    "\n",
    "    yolo_start = time.time()\n",
    "    boxes, scores, classes, nums = yolo.predict(img_in) # yolo prediction\n",
    "    yolo_end = time.time()\n",
    "\n",
    "    tracking_start = time.time()\n",
    "    dets = boxes[:,:nums[0],:].reshape(nums[0], 4)  # filter pedestrians\n",
    "    trackers = mot_tracker.update(dets[classes[0][:nums[0]] == 0]) # track the pedestrians\n",
    "    tracking_end = time.time()\n",
    "\n",
    "    postprocess_start = time.time()\n",
    "    for d in trackers:\n",
    "\n",
    "      wh = np.flip(img.shape[0:2])\n",
    "      x1y1 = tuple((np.array(d[0:2]) * wh).astype(np.int32))\n",
    "      x2y2 = tuple((np.array(d[2:4]) * wh).astype(np.int32))\n",
    "\n",
    "      y = 0\n",
    "\n",
    "      if int(d[4]) in list(rolling_data.keys()):\n",
    "\n",
    "        if len(rolling_data[int(d[4])]) == 16:\n",
    "\n",
    "          seq = np.stack(np.array(rolling_data[int(d[4])]),axis=2) # (100*100*16*3)\n",
    "          seq = np.expand_dims(seq, axis=0)\n",
    "          y = pred_func(seq) # classification output\n",
    "\n",
    "        else:\n",
    "\n",
    "          seq = np.stack(np.array([rolling_data[int(d[4])][-1]] * 16),axis=2)\n",
    "          seq = np.expand_dims(seq, axis=0)\n",
    "          y = pred_func(seq) # classification output\n",
    "\n",
    "      # risky pedestrian identification thru box color\n",
    "\n",
    "      if frame not in predictions:\n",
    "        predictions[frame] = []  # Initialize list if frame key is missing\n",
    "\n",
    "      predictions[frame].append({\"bbox\": [x1y1[0], x1y1[1], x2y2[0], x2y2[1]], \"cross_pred\": int(y)})\n",
    "\n",
    "\n",
    "      if y == 1:\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "      else:\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "      image = cv2.rectangle(img, x1y1, x2y2, color, thickness)\n",
    "      image = cv2.putText(image, str(int(d[4])), org = (x1y1[0],x1y1[1]-5) , fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=color, thickness=thickness)\n",
    "      image = cv2.putText(image, \"Frame No: {}\".format(frame), (0, 30),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 0), 2)\n",
    "\n",
    "      # storing the data for last 16 frames\n",
    "      try:\n",
    "\n",
    "        if int(d[4]) in list(rolling_data.keys()): # ID exists in dict\n",
    "\n",
    "          if len(rolling_data[int(d[4])]) < 16: # bboxes values for 16 frames\n",
    "\n",
    "            cropped_seq = []\n",
    "            cropped_img = cv2.resize(img_orig[x1y1[1]:x2y2[1], x1y1[0]:x2y2[0]],(100,100))\n",
    "            rolling_data[int(d[4])].append(np.asarray(cropped_img)) # append the image\n",
    "\n",
    "          else:\n",
    "\n",
    "            del rolling_data[int(d[4])][0] # delete oldest frame bbox and append latest frame bbox\n",
    "            cropped_seq = []\n",
    "            cropped_img = cv2.resize(img_orig[x1y1[1]:x2y2[1], x1y1[0]:x2y2[0]],(100,100))\n",
    "            rolling_data[int(d[4])].append(np.asarray(cropped_img))\n",
    "\n",
    "        else:\n",
    "\n",
    "          cropped_seq = []\n",
    "          cropped_img = cv2.resize(img_orig[x1y1[1]:x2y2[1], x1y1[0]:x2y2[0]],(100,100))\n",
    "          rolling_data[int(d[4])] = [np.asarray(cropped_img)]\n",
    "      except:\n",
    "        pass\n",
    "    postprocess_end = time.time()\n",
    "\n",
    "    if FLAGS.output:\n",
    "      out.write(img)\n",
    "    #cv2.imshow('output', img)\n",
    "\n",
    "    print(f\"Frame {frame}:\")\n",
    "    print(f\"  Preprocessing Time: {preprocess_end - preprocess_start:.4f} sec\")\n",
    "    print(f\"  YOLO Prediction Time: {yolo_end - yolo_start:.4f} sec\")\n",
    "    print(f\"  Tracking Time: {tracking_end - tracking_start:.4f} sec\")\n",
    "    print(f\"  Post-processing Time: {postprocess_end - postprocess_start:.4f} sec\")\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "      break\n",
    "\n",
    "  # **Save predictions after loop**\n",
    "  import pickle\n",
    "  with open(\"predictions.pkl\", \"wb\") as f:\n",
    "      pickle.dump(predictions, f)\n",
    "\n",
    "  print(\"Predictions saved successfully!\")\n",
    "\n",
    "  cv2.destroyAllWindows()\n",
    "  print('\\nProcessing completed.......!!!')\n",
    "  print('Check video file in Pedestrian_Behaviour_Prediction folder!')\n",
    "\n",
    "  return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two bounding boxes.\"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1, yi1 = max(x1, x1g), max(y1, y1g)\n",
    "    xi2, yi2 = min(x2, x2g), min(y2, y2g)\n",
    "\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def match_predictions(gt_data, pred_data, iou_threshold=0.5):\n",
    "    matched = []\n",
    "\n",
    "    for frame in pred_data:\n",
    "        if frame in gt_data:\n",
    "            for pred in pred_data[frame]:\n",
    "                best_iou = 0\n",
    "                best_match = None\n",
    "\n",
    "                for gt in gt_data[frame]:\n",
    "                    iou = compute_iou(pred[\"bbox\"], gt[\"bbox\"])\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_match = gt\n",
    "\n",
    "                if best_iou >= iou_threshold and best_match:\n",
    "                    matched.append((best_match[\"cross\"], pred[\"cross_pred\"]))  # (GT label, Prediction)\n",
    "\n",
    "    return matched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load ground truth annotations\n",
    "with open(\"gt_annotations.pkl\", \"rb\") as f:\n",
    "    gt_annotations = pickle.load(f)\n",
    "\n",
    "# Load model predictions\n",
    "with open(\"predictions.pkl\", \"rb\") as f:\n",
    "    predictions = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Match ground truth and predictions\n",
    "matched_labels = match_predictions(gt_annotations, predictions)\n",
    "\n",
    "# Extract true labels (y_true) and predicted labels (y_pred)\n",
    "y_true = [gt for gt, pred in matched_labels]\n",
    "y_pred = [pred for gt, pred in matched_labels]\n",
    "\n",
    "# Compute performance metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \"Precision\": precision_score(y_true, y_pred),\n",
    "    \"Recall\": recall_score(y_true, y_pred),\n",
    "    \"F1-Score\": f1_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for table format\n",
    "metrics_df = pd.DataFrame(metrics.items(), columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "# Print formatted table\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
